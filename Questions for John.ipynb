{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:#e6fee6;color:black\"><pre>Packages already installed: imutils, jupyterthemes, numpy, opencv-python, pandas</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:lightyellow;color:black\"><pre>No new packages installed</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:#eee;color:black\"><pre>Done</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipydeps\n",
    "ipydeps.pip(['imutils'\n",
    "             ,'jupyterthemes'\n",
    "             ,'numpy'\n",
    "             ,'opencv-python'\n",
    "             ,'pandas'])\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select video input (i.e. cam, CPUs.MOV, Fullfield.mp4): /Sample Videos/CPUs.MOV\n",
      "Capture set to:  /Users/sallgaier96/Desktop/Career/Personal/Projects/Monocle/Computer Vision//Sample Videos/CPUs.MOV\n"
     ]
    }
   ],
   "source": [
    "# Read in recorded video file\n",
    "frameWidth = 320\n",
    "frameHeight = 320\n",
    "cwd = os.getcwd()\n",
    "\n",
    "filename = input('Select video input (i.e. cam, CPUs.MOV, Fullfield.mp4): ')\n",
    "filename = (cwd + '/' +filename)\n",
    "cap = cv2.VideoCapture(filename)\n",
    "if os.path.isfile(filename) and os.access(filename, os.R_OK):\n",
    "    print('Capture set to: ', filename)\n",
    "else:\n",
    "    print('File does not exist or not readable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Object Detection: currently using YOLOv3\n",
    "# Better accuracy? Sometimes people/ball not being detected, 14-19 people detected when expecting23\n",
    "# Faster speed? Current processing rate is 3-5 fps without great accuracy\n",
    "\n",
    "# YOLO v3 or YOLO v4 or YOLO v5 or YOLO PP\n",
    "# Look for sports ball and person type objects (outputs[5] and outputs[38])\n",
    "# outputs[0] is cx: x coordinate of detected object\n",
    "# outputs[1] is cy: y coordinate of detected object\n",
    "# outputs[2] is w: width of detected object\n",
    "# outputs[3] is h: height of detected object\n",
    "# outputs[4] is confidence: likelihood that object is present\n",
    "# rest are likelihood of defined objects in coco file found in classNames array\n",
    "\n",
    "whT = 320 # using the same height and width, change for video size\n",
    "confThreshold = 0.5 # higher = more confidence required\n",
    "nmsThreshold = 0.3 # lower = less boxes, higher = more boxes\n",
    "\n",
    "classNames = []\n",
    "classNames = pd.read_csv('coco.names', header = None)\n",
    "classNames = classNames[(classNames[0] == 'person') | (classNames[0] == 'sports ball')]\n",
    "# Now the only two objects that we're looking for are sports ball and person\n",
    "\n",
    "# Slower frame rate, higher accuracy\n",
    "modelConfiguration = 'yolov3-320.cfg';\n",
    "modelWeights = 'yolov3.weights';\n",
    "# Faster frame rate, lower accuracy\n",
    "# modelConfiguration = 'yolov3-tiny.cfg';\n",
    "# modelWeidghts = 'yolov3-tiny.weights';\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "def findObjects(outputs, img):\n",
    "    hT, wT, cT = img.shape # height, width, and channels of image\n",
    "    bbox = [] # contains height and width\n",
    "    classIds = []\n",
    "    confs = []\n",
    "    \n",
    "    for output in outputs: # FOR LOOP HERE ###\n",
    "        for det in output: # FOR LOOP HERE ###\n",
    "            scores = det[5:] # removes first five elements\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                w,h = int(det[2]*wT), int(det[3]*hT)\n",
    "                x,y = int((det[0]*wT)-w/2), int((det[1]*hT)-h/2)\n",
    "                bbox.append([x,y,w,h])\n",
    "                classIds.append(classId)\n",
    "                confs.append(float(confidence))\n",
    "#     print(len(bbox)) # prints how many objects were detected in each frame\n",
    "    indices = cv2.dnn.NMSBoxes(bbox, confs, confThreshold, nmsThreshold) # indices to keep\n",
    "#     print(indices)\n",
    "    for i in indices: # FOR LOOP HERE ###\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0], box[1], box[2], box[3]\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2) # BGR color value\n",
    "#         cv2.putText(frame, f'{classNames[classIds[i]].str.upper()} {int(confs[i]*100)}%',\n",
    "#                    (x,y-10), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,0,255), 2) # Printing too much\n",
    "\n",
    "# def yoloDetection():\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (whT, whT), [0,0,0], 1, crop = False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    layerNames = net.getLayerNames()\n",
    "    net.getUnconnectedOutLayers() # This gives the pixel coordinates of objects\n",
    "    outputNames = [layerNames[i[0]-1] for i in net.getUnconnectedOutLayers()] # Name and coordinate\n",
    "#     print(outputNames)\n",
    "    outputs = net.forward(outputNames)\n",
    "    findObjects(outputs, frame)\n",
    "\n",
    "    cv2.imshow('YOLO Object Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27: # Esc key to exit\n",
    "            break\n",
    "\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to rectify image to be square like bird's eye view\n",
    "# Here is a link of what I'm looking for and three potential options\n",
    "# https://towardsdatascience.com/how-to-track-football-players-using-yolo-sort-and-opencv-6c58f71120b8\n",
    "\n",
    "# https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#getperspectivetransform\n",
    "# src = Coordinates of quadrangle vertices in source image\n",
    "# dst = Coordinates of corresponding quadrangle vertices in destination image\n",
    "cv2.GetPerspectiveTransform(src, dst, mapMatrix)\n",
    "\n",
    "# https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#Mat%20findHomography(InputArray%20srcPoints,%20InputArray%20dstPoints,%20int%20method,%20double%20ransacReprojThreshold,%20OutputArray%20mask)\n",
    "# method can be 0 (regular method), CV_RANSAC (robust), CV_LMEDS (robust)\n",
    "cv.FindHomography(src, dst, H, method = 0, ransacReprojThreshold = 3.0, status = None)\n",
    "\n",
    "# https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#void%20warpPerspective(InputArray%20src,%20OutputArray%20dst,%20InputArray%20M,%20Size%20dsize,%20int%20flags,%20int%20borderMode,%20const%20Scalar&%20borderValue)\n",
    "# M = 3x3 transformation matrix\n",
    "# dsize = size of output image\n",
    "# flags = ???\n",
    "# borderMode = pixel extrapolation method (BORDER_CONSTANT / BORDER_REPLICATE)\n",
    "# borderValue = value used in case of constant border, default = 0\n",
    "cv2.warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
